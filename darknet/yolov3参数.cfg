[net]
# Testing            ### 测试模式                                          ★★★
 batch=1
 subdivisions=1
# Training           ### 训练模式，每次前向的图片数目 = batch/subdivisions ★★★
# batch=64
# subdivisions=16
width=416            ### 网络的输入宽、高、通道数                          ★★
height=416
channels=3
momentum=0.9         ### 动量，影响着梯度下降到最优值的速度                                         ★
decay=0.0005         ### 权重衰减 ，防止过拟合                                         ★
angle=0              ### 通过旋转角度来生成最多训练样本
saturation = 1.5     ### 饱和度 。通过调整饱和度来生成更多训练样本                                         ★
exposure = 1.5       ### 曝光度  ，来生成更多训练样本                                           ★
hue=.1               ### 色调  ，来生成更多训练样本                                             ★

learning_rate=0.001  ### 学习率 ，决定这权值更新的速度，设置                                         ★★★
burn_in=1000         ### 学习率控制的参数
max_batches = 50200  ### 迭代次数                                          ★★★
policy=steps         ### 学习率策略                                        ★★
steps=40000,45000    ### 学习率变动步长                                    ★★
scales=.1,.1         ### 学习率变动因子                                    ★★


#输入：416*416*3
[convolutional]
batch_normalize=1    ### BN
filters=32           ### 卷积核数目
size=3               ### 卷积核尺寸
stride=1             ### 卷积核步长
pad=1                ### pad
activation=leaky     ### 激活函数
##0 输出：416*416*32
# Downsample

[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky
#1 输出：416*416*64

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky
#2  输出：208*208*32

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky
#3 输出：208*208*64

[shortcut]
from=-3
activation=linear
#4 输出：208*208*64，当前层和往前3层卷积层，组合成残差神经块，比如此时即为第一个卷积层1。

# Downsample
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky
#5 输出：104*104*128

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky
#6 输出：104*104*64

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky
#7，输出：104*104*128

[shortcut]
from=-3              ### 连接层
activation=linear
#8 输出：104*104*128

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky
#9输出：104*104*64

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky
#10输出：104*104*128

[shortcut]
from=-3
activation=linear
#11输出：104*104*128
# Downsample

[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky
#12输出：52*52*128

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#13 输出：52*52*128

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
#14,52*52*256

[shortcut]
from=-3
activation=linear
#15 52*52*256

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#16 52*52*128

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
#17 52*52*256

[shortcut]
from=-3
activation=linear
# 18 52*52*256

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#19 52*52*128

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
#20 52*52*256

[shortcut]
from=-3
activation=linear
#21 52*52*256

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#22 52*52*128

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
#23 52*52*256

[shortcut]
from=-3
activation=linear
#24 52*52*256

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#25 52*52*128

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
#26 52*52*256

[shortcut]
from=-3
activation=linear
#27 52*52*256

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#28 52*52*128

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
#29 52*52*256

[shortcut]
from=-3
activation=linear
#30 52*52*256

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#31 52*52*128

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
#32 52*52*256

[shortcut]
from=-3
activation=linear
#33 52*52*256

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#34 52*52*128

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
#35 52*52*256

[shortcut]
from=-3
activation=linear
#36 52*52*256
# Downsample

[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky
#37 26*26*512

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#38 26*26*256

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
#39 26*26*512

[shortcut]
from=-3
activation=linear
#40 26*26*512

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#41 26*26*256

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
#42 26*26*512

[shortcut]
from=-3
activation=linear
#43 26*26*512

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#44 26*26*256

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
#45 26*26*512

[shortcut]
from=-3
activation=linear
#45626*26*512

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#47 26*26*512

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
#48 26*26*512

[shortcut]
from=-3
activation=linear
#49 26*26*512

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#50 26*26*256

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
#51 26*26*512

[shortcut]
from=-3
activation=linear
#52 26*26*512

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#53 26*26*256

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
#54 26*26*512

[shortcut]
from=-3
activation=linear
#55 26*26*512

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#56 26*26*256

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
#57 26*26*512

[shortcut]
from=-3
activation=linear
#58 26*26*512

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#59 26*26*256

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
#60 26*26*512

[shortcut]
from=-3
activation=linear
#61 26*26*512
# Downsample

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=leaky
#62 13*13*1024

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
#63 13*13*512

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky
#64 13*13*1024

[shortcut]
from=-3
activation=linear
#65 13*13*1024

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
#66 13*13*512

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky
#67 13*13*1024

[shortcut]
from=-3
activation=linear
#68 13*13*1024

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
#69 13*13*512

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky
#70 13*13*1024

[shortcut]
from=-3
activation=linear
#71 13*13*1024

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
#72 13*13*512

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky
#73 13*13*1024

[shortcut]
from=-3
activation=linear
#74 13*13*1024
######################

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
#75 13*13*512

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky
#76 13*13*1024

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
#77 13*13*512

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky
#78 13*13*1024

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
#79 13*13*512

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky
#80 13*13*1024

[convolutional]
size=1
stride=1
pad=1
filters=75                                             ★★★需要修改的地方也，和类别个数有关系/75=3*（20+1+4）
activation=linear
#81 13*13*75

[yolo]
mask = 6,7,8
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=20                                             ★★★
num=9            ##每个grid cell 预测几个box，和anchors的数量一致，
jitter=.3
ignore_thresh = .5
truth_thresh = 1
random=1                                               ★★★
#82 detection

[route]
layers = -4
#83层，13*13*512，由来：往前推4层到79（13*13*512），我认为此层是把79层的输出结果之间转到此处。

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#84 13*13*256

[upsample]
stride=2
#85 26*26*256 上采样，upsample *2

[route]
layers = -1, 61
#86 26*26*768 将85层和61层合并起来，26*26*（512+256）

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#87 26*26*256

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky
#88 26*26*512

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#89 26*26*256

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky
#90 26*26*512

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
#91 26*26*256

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky
#92 26*26*512

[convolutional]
size=1
stride=1
pad=1
filters=75                                                  ★★★需要根据类别进行修改
activation=linear
#93 26*26*75

[yolo]
mask = 3,4,5
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=20                                                  ★★★
num=9
jitter=.3
ignore_thresh = .5
truth_thresh = 1
random=1                                                    ★★★
#94 detection

[route]
layers = -4
#95 连接91层，26*26*256

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
# 96 26*26*128

[upsample]
stride=2
#97 上采样，*2 52*52*256

[route]
layers = -1, 36
#98 连接97和36层进行合并为：52*52*（256+128）=52*52*384


[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#99 52*52*128

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky
#100 52*52*256

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#101 52*52*128

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky
# 102 52*52*256

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
#103 52*52*128

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky
#104 52*52*256

[convolutional]
size=1
stride=1
pad=1
filters=75              ### 3x(classes + 4coor + 1prob) = 3x(20+4+1) = 75              ★★★
activation=linear
#105 52*52*75

[yolo]
mask = 0,1,2            ### mask序号                        ★
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326  ★★★
classes=20              ### 类比数目                        ★★★
num=9
jitter=.3               ### 数据扩充的抖动操作              ★
ignore_thresh = .5      ### 文章中的阈值1                   ★
truth_thresh = 1        ### 文章中的阈值2                   ★
random=1                ### 多尺度训练开关                  ★★★
#106 detection
